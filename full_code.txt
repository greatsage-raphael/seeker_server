// FILE: .gitignore
// --------------------------------------------------------------------------

# compiled output
/dist
/node_modules
/build

# Logs
logs
*.log
npm-debug.log*
pnpm-debug.log*
yarn-debug.log*
yarn-error.log*
lerna-debug.log*

# OS
.DS_Store

# Tests
/coverage
/.nyc_output

# IDEs and editors
/.idea
.project
.classpath
.c9/
*.launch
.settings/
*.sublime-workspace

# IDE - VSCode
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json

# dotenv environment variable files
.env
.env.development.local
.env.test.local
.env.production.local
.env.local

# temp directory
.temp
.tmp

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Diagnostic reports (https://nodejs.org/api/report.html)
report.[0-9]*.[0-9]*.[0-9]*.[0-9]*.json


// END OF FILE: .gitignore
// ==========================================================================

// FILE: .prettierrc
// --------------------------------------------------------------------------

{
  "singleQuote": true,
  "trailingComma": "all"
}


// END OF FILE: .prettierrc
// ==========================================================================

// FILE: README.md
// --------------------------------------------------------------------------

<p align="center">
  <a href="http://nestjs.com/" target="blank"><img src="https://nestjs.com/img/logo-small.svg" width="120" alt="Nest Logo" /></a>
</p>

[circleci-image]: https://img.shields.io/circleci/build/github/nestjs/nest/master?token=abc123def456
[circleci-url]: https://circleci.com/gh/nestjs/nest

  <p align="center">A progressive <a href="http://nodejs.org" target="_blank">Node.js</a> framework for building efficient and scalable server-side applications.</p>
    <p align="center">
<a href="https://www.npmjs.com/~nestjscore" target="_blank"><img src="https://img.shields.io/npm/v/@nestjs/core.svg" alt="NPM Version" /></a>
<a href="https://www.npmjs.com/~nestjscore" target="_blank"><img src="https://img.shields.io/npm/l/@nestjs/core.svg" alt="Package License" /></a>
<a href="https://www.npmjs.com/~nestjscore" target="_blank"><img src="https://img.shields.io/npm/dm/@nestjs/common.svg" alt="NPM Downloads" /></a>
<a href="https://circleci.com/gh/nestjs/nest" target="_blank"><img src="https://img.shields.io/circleci/build/github/nestjs/nest/master" alt="CircleCI" /></a>
<a href="https://discord.gg/G7Qnnhy" target="_blank"><img src="https://img.shields.io/badge/discord-online-brightgreen.svg" alt="Discord"/></a>
<a href="https://opencollective.com/nest#backer" target="_blank"><img src="https://opencollective.com/nest/backers/badge.svg" alt="Backers on Open Collective" /></a>
<a href="https://opencollective.com/nest#sponsor" target="_blank"><img src="https://opencollective.com/nest/sponsors/badge.svg" alt="Sponsors on Open Collective" /></a>
  <a href="https://paypal.me/kamilmysliwiec" target="_blank"><img src="https://img.shields.io/badge/Donate-PayPal-ff3f59.svg" alt="Donate us"/></a>
    <a href="https://opencollective.com/nest#sponsor"  target="_blank"><img src="https://img.shields.io/badge/Support%20us-Open%20Collective-41B883.svg" alt="Support us"></a>
  <a href="https://twitter.com/nestframework" target="_blank"><img src="https://img.shields.io/twitter/follow/nestframework.svg?style=social&label=Follow" alt="Follow us on Twitter"></a>
</p>
  <!--[![Backers on Open Collective](https://opencollective.com/nest/backers/badge.svg)](https://opencollective.com/nest#backer)
  [![Sponsors on Open Collective](https://opencollective.com/nest/sponsors/badge.svg)](https://opencollective.com/nest#sponsor)-->

## Description

[Nest](https://github.com/nestjs/nest) framework TypeScript starter repository.

## Project setup

```bash
$ npm install
```

## Compile and run the project

```bash
# development
$ npm run start

# watch mode
$ npm run start:dev

# production mode
$ npm run start:prod
```

## Run tests

```bash
# unit tests
$ npm run test

# e2e tests
$ npm run test:e2e

# test coverage
$ npm run test:cov
```

## Deployment

When you're ready to deploy your NestJS application to production, there are some key steps you can take to ensure it runs as efficiently as possible. Check out the [deployment documentation](https://docs.nestjs.com/deployment) for more information.

If you are looking for a cloud-based platform to deploy your NestJS application, check out [Mau](https://mau.nestjs.com), our official platform for deploying NestJS applications on AWS. Mau makes deployment straightforward and fast, requiring just a few simple steps:

```bash
$ npm install -g @nestjs/mau
$ mau deploy
```

With Mau, you can deploy your application in just a few clicks, allowing you to focus on building features rather than managing infrastructure.

## Resources

Check out a few resources that may come in handy when working with NestJS:

- Visit the [NestJS Documentation](https://docs.nestjs.com) to learn more about the framework.
- For questions and support, please visit our [Discord channel](https://discord.gg/G7Qnnhy).
- To dive deeper and get more hands-on experience, check out our official video [courses](https://courses.nestjs.com/).
- Deploy your application to AWS with the help of [NestJS Mau](https://mau.nestjs.com) in just a few clicks.
- Visualize your application graph and interact with the NestJS application in real-time using [NestJS Devtools](https://devtools.nestjs.com).
- Need help with your project (part-time to full-time)? Check out our official [enterprise support](https://enterprise.nestjs.com).
- To stay in the loop and get updates, follow us on [X](https://x.com/nestframework) and [LinkedIn](https://linkedin.com/company/nestjs).
- Looking for a job, or have a job to offer? Check out our official [Jobs board](https://jobs.nestjs.com).

## Support

Nest is an MIT-licensed open source project. It can grow thanks to the sponsors and support by the amazing backers. If you'd like to join them, please [read more here](https://docs.nestjs.com/support).

## Stay in touch

- Author - [Kamil My≈õliwiec](https://twitter.com/kammysliwiec)
- Website - [https://nestjs.com](https://nestjs.com/)
- Twitter - [@nestframework](https://twitter.com/nestframework)

## License

Nest is [MIT licensed](https://github.com/nestjs/nest/blob/master/LICENSE).


// END OF FILE: README.md
// ==========================================================================

// FILE: eslint.config.mjs
// --------------------------------------------------------------------------

// @ts-check
import eslint from '@eslint/js';
import eslintPluginPrettierRecommended from 'eslint-plugin-prettier/recommended';
import globals from 'globals';
import tseslint from 'typescript-eslint';

export default tseslint.config(
  {
    ignores: ['eslint.config.mjs'],
  },
  eslint.configs.recommended,
  ...tseslint.configs.recommendedTypeChecked,
  eslintPluginPrettierRecommended,
  {
    languageOptions: {
      globals: {
        ...globals.node,
        ...globals.jest,
      },
      sourceType: 'commonjs',
      parserOptions: {
        projectService: true,
        tsconfigRootDir: import.meta.dirname,
      },
    },
  },
  {
    rules: {
      '@typescript-eslint/no-explicit-any': 'off',
      '@typescript-eslint/no-floating-promises': 'warn',
      '@typescript-eslint/no-unsafe-argument': 'warn'
    },
  },
);


// END OF FILE: eslint.config.mjs
// ==========================================================================

// FILE: nest-cli.json
// --------------------------------------------------------------------------

{
  "$schema": "https://json.schemastore.org/nest-cli",
  "collection": "@nestjs/schematics",
  "sourceRoot": "src",
  "compilerOptions": {
    "deleteOutDir": true
  }
}


// END OF FILE: nest-cli.json
// ==========================================================================

// FILE: package.json
// --------------------------------------------------------------------------

{
  "name": "seeker-server",
  "version": "0.0.1",
  "description": "",
  "author": "",
  "private": true,
  "license": "UNLICENSED",
  "scripts": {
    "build": "nest build",
    "format": "prettier --write \"src/**/*.ts\" \"test/**/*.ts\"",
    "start": "nest start",
    "start:dev": "nest start --watch",
    "start:debug": "nest start --debug --watch",
    "start:prod": "node dist/main",
    "lint": "eslint \"{src,apps,libs,test}/**/*.ts\" --fix",
    "test": "jest",
    "test:watch": "jest --watch",
    "test:cov": "jest --coverage",
    "test:debug": "node --inspect-brk -r tsconfig-paths/register -r ts-node/register node_modules/.bin/jest --runInBand",
    "test:e2e": "jest --config ./test/jest-e2e.json"
  },
  "dependencies": {
    "@google/genai": "^1.34.0",
    "@nestjs/common": "^11.0.1",
    "@nestjs/config": "^4.0.2",
    "@nestjs/core": "^11.0.1",
    "@nestjs/platform-express": "^11.0.1",
    "@supabase/supabase-js": "^2.90.0",
    "dotenv": "^17.2.3",
    "ffmpeg-static": "^5.3.0",
    "fluent-ffmpeg": "^2.1.3",
    "reflect-metadata": "^0.2.2",
    "rxjs": "^7.8.1"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3.2.0",
    "@eslint/js": "^9.18.0",
    "@nestjs/cli": "^11.0.0",
    "@nestjs/schematics": "^11.0.0",
    "@nestjs/testing": "^11.0.1",
    "@types/express": "^5.0.0",
    "@types/jest": "^30.0.0",
    "@types/node": "^22.10.7",
    "@types/supertest": "^6.0.2",
    "eslint": "^9.18.0",
    "eslint-config-prettier": "^10.0.1",
    "eslint-plugin-prettier": "^5.2.2",
    "globals": "^16.0.0",
    "jest": "^30.0.0",
    "prettier": "^3.4.2",
    "source-map-support": "^0.5.21",
    "supertest": "^7.0.0",
    "ts-jest": "^29.2.5",
    "ts-loader": "^9.5.2",
    "ts-node": "^10.9.2",
    "tsconfig-paths": "^4.2.0",
    "typescript": "^5.7.3",
    "typescript-eslint": "^8.20.0"
  },
  "jest": {
    "moduleFileExtensions": [
      "js",
      "json",
      "ts"
    ],
    "rootDir": "src",
    "testRegex": ".*\\.spec\\.ts$",
    "transform": {
      "^.+\\.(t|j)s$": "ts-jest"
    },
    "collectCoverageFrom": [
      "**/*.(t|j)s"
    ],
    "coverageDirectory": "../coverage",
    "testEnvironment": "node"
  }
}


// END OF FILE: package.json
// ==========================================================================

// FILE: run.js
// --------------------------------------------------------------------------

const fs = require('fs');
const path = require('path');

// --- Configuration ---

// The name of the output file.
const outputFile = 'full_code.txt';

// The root directory of your project. '.' means the current directory.
const rootDir = '.';

// List of directories to completely ignore.
const ignoreDirs = [
  'node_modules',
  '.next',
  '.git',
  '.vscode',
  '.swc',
  'dist',
  'build',
  'temp'
  // Add any other directories you want to ignore
];

// List of specific files or file extensions to ignore.
const ignoreFiles = [
  outputFile,          // Don't include the output file itself
  'package-lock.json',
  'yarn.lock',
  'pnpm-lock.yaml',
  'tsconfig.tsbuildinfo',
  '.env',
  '.env.local',
  // Add any other specific files you want to ignore
];

const ignoreExtensions = [
    '.png', '.jpg', '.jpeg', '.gif', '.svg', '.ico', // Images
    '.woff', '.woff2', '.ttf', '.eot', // Fonts
    '.mp4', '.webm', // Videos
    '.zip', '.gz', // Archives
];


// --- Script Logic ---

let finalContent = '';

function walkDir(currentPath) {
  const files = fs.readdirSync(currentPath);

  for (const file of files) {
    const filePath = path.join(currentPath, file);
    const stat = fs.statSync(filePath);

    if (stat.isDirectory()) {
      // If it's a directory, check if it's in the ignore list.
      if (!ignoreDirs.includes(file)) {
        // If not ignored, recurse into it.
        walkDir(filePath);
      }
    } else {
      // It's a file. Check if it or its extension is in the ignore lists.
      const fileExtension = path.extname(file).toLowerCase();
      if (!ignoreFiles.includes(file) && !ignoreExtensions.includes(fileExtension)) {
        try {
          const content = fs.readFileSync(filePath, 'utf8');
          
          finalContent += `// FILE: ${filePath}\n`;
          finalContent += `// --------------------------------------------------------------------------\n\n`;
          finalContent += content;
          finalContent += `\n\n// END OF FILE: ${filePath}\n`;
          finalContent += `// ==========================================================================\n\n`;

        } catch (error) {
            // This can happen for binary files that aren't caught by the extension filter
            console.log(`Could not read file (likely binary): ${filePath}`);
        }
      }
    }
  }
}

try {
  console.log('Starting to bundle project files...');
  // Start the process from the root directory.
  walkDir(rootDir);

  // Write the aggregated content to the output file.
  fs.writeFileSync(outputFile, finalContent);

  console.log(`‚úÖ Successfully created ${outputFile}`);
  console.log('Remember to review the file for any sensitive information before sharing.');

} catch (error) {
  console.error('‚ùå An error occurred:', error);
}

// END OF FILE: run.js
// ==========================================================================

// FILE: src/app.controller.spec.ts
// --------------------------------------------------------------------------

import { Test, TestingModule } from '@nestjs/testing';
import { AppController } from './app.controller';
import { AppService } from './app.service';

describe('AppController', () => {
  let appController: AppController;

  beforeEach(async () => {
    const app: TestingModule = await Test.createTestingModule({
      controllers: [AppController],
      providers: [AppService],
    }).compile();

    appController = app.get<AppController>(AppController);
  });

  describe('root', () => {
    it('should return "Hello World!"', () => {
      expect(appController.getHello()).toBe('Hello World!');
    });
  });
});


// END OF FILE: src/app.controller.spec.ts
// ==========================================================================

// FILE: src/app.controller.ts
// --------------------------------------------------------------------------

import { Controller, Get } from '@nestjs/common';
import { AppService } from './app.service';

@Controller()
export class AppController {
  constructor(private readonly appService: AppService) {}

  @Get()
  getHello(): string {
    return this.appService.getHello();
  }
}


// END OF FILE: src/app.controller.ts
// ==========================================================================

// FILE: src/app.module.ts
// --------------------------------------------------------------------------

import { Module } from '@nestjs/common';
import { ConfigModule } from '@nestjs/config';
import { SlidesModule } from './slides/slides.module';
import { VideoModule } from './video/video.module';

@Module({
  imports: [
    ConfigModule.forRoot({ isGlobal: true }), // Loads your .env file
    SlidesModule,
    VideoModule,
  ],
})
export class AppModule {}


// END OF FILE: src/app.module.ts
// ==========================================================================

// FILE: src/app.service.ts
// --------------------------------------------------------------------------

import { Injectable } from '@nestjs/common';

@Injectable()
export class AppService {
  getHello(): string {
    return 'Hello World!';
  }
}


// END OF FILE: src/app.service.ts
// ==========================================================================

// FILE: src/main.ts
// --------------------------------------------------------------------------

// FILE: src/main.ts
import { NestFactory } from '@nestjs/core';
import { AppModule } from './app.module';

async function bootstrap() {
  const app = await NestFactory.create(AppModule);
  
  // FIX: Enable CORS so your frontend (3000) can talk to your backend (3001)
  app.enableCors({
    origin: 'https://seeker-prime.vercel.app',
    methods: 'GET,HEAD,PUT,PATCH,POST,DELETE',
    credentials: true,
  });

  // Change port to 3001 to avoid conflict with React
  await app.listen(3001); 
  console.log('Seeker Backend running on http://localhost:3001');
}
bootstrap();


// END OF FILE: src/main.ts
// ==========================================================================

// FILE: src/slides/slides.controller.ts
// --------------------------------------------------------------------------

import { Controller, Post, Body } from '@nestjs/common';
import { SlidesService } from './slides.service';

@Controller('slides')
export class SlidesController {
  constructor(private readonly slidesService: SlidesService) {}

  @Post('generate')
  async generate(@Body() body: { lessonId: string; summary: string; thoughts: string; title: string }) {
    // We run this asynchronously so the frontend doesn't time out
    this.slidesService.createVideo(body.lessonId, body.summary, body.thoughts, body.title);
    return { message: 'Generation started' };
  }

  @Post('generate-podcast')
async generatePodcast(@Body() body: { lessonId: string; summary: string; title: string }) {
  // Run async so frontend doesn't hang
  this.slidesService.createPodcast(body.lessonId, body.summary, body.title);
  return { message: 'Podcast generation started' };
}

// src/slides/slides.controller.ts

@Post('generate-comic')
async generateComic(@Body() body: { lessonId: string; ai_notes: string; title: string }) {
  console.log(`[Controller] Incoming Comic Request for Lesson: ${body.lessonId}`);
  // Pass ai_notes specifically to the service
  this.slidesService.createComic(body.lessonId, body.ai_notes, body.title);
  return { message: 'Comic book production initiated' };
}

@Post('generate-tree')
async generateTree(@Body() body: { courseId: string }) {
  await this.slidesService.generateSkillTree(body.courseId);
  return { status: 'done' };
}
}

// END OF FILE: src/slides/slides.controller.ts
// ==========================================================================

// FILE: src/slides/slides.module.ts
// --------------------------------------------------------------------------

import { Module } from '@nestjs/common';
import { SlidesController } from './slides.controller';
import { SlidesService } from './slides.service';

@Module({
  controllers: [SlidesController],
  providers: [SlidesService],
})
export class SlidesModule {}

// END OF FILE: src/slides/slides.module.ts
// ==========================================================================

// FILE: src/slides/slides.service.ts
// --------------------------------------------------------------------------

import { Injectable, OnModuleInit } from '@nestjs/common';
import { createClient } from '@supabase/supabase-js';
import * as fs from 'fs';
import * as path from 'path';
import ffmpeg from 'fluent-ffmpeg';
import { exec } from 'child_process';
import { promisify } from 'util';

const execAsync = promisify(exec);

@Injectable()
export class SlidesService implements OnModuleInit {
    private supabase = createClient(process.env.SUPABASE_URL!, process.env.SUPABASE_SERVICE_ROLE_KEY!);
    private processingQueue = new Set<string>();

    async onModuleInit() {
        // Use system FFmpeg instead of ffmpeg-static
        try {
            const { stdout } = await execAsync('which ffmpeg');
            const systemFfmpegPath = stdout.trim();
            ffmpeg.setFfmpegPath(systemFfmpegPath);
            console.log('‚úÖ Using System FFmpeg:', systemFfmpegPath);

            // Verify drawtext filter exists
            const { stdout: filters } = await execAsync('ffmpeg -filters 2>&1 | grep drawtext');
            if (filters.includes('drawtext')) {
                console.log('‚úÖ drawtext filter available');
            } else {
                console.error('‚ùå drawtext filter NOT available - install full FFmpeg');
            }
        } catch (e) {
            console.error('‚ö†Ô∏è  System FFmpeg not found. Install with: sudo apt install ffmpeg');
        }
    }

    private getSystemFont() {
        const paths = [
            '/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf',
            '/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf',
            '/System/Library/Fonts/Supplemental/Arial Bold.ttf',
        ];
        for (const p of paths) {
            if (fs.existsSync(p)) {
                console.log('‚úÖ Using font:', p);
                return p;
            }
        }
        console.warn('‚ö†Ô∏è  No system font found, using Arial');
        return 'Arial';
    }

    private async getGoogleGenAI() {
        const { GoogleGenAI } = await import('@google/genai');
        return new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY! });
    }

    async createVideo(lessonId: string, summary: string, thoughts: string, title: string) {
        if (this.processingQueue.has(lessonId)) return;
        this.processingQueue.add(lessonId);

        const tempDir = path.resolve(process.cwd(), 'temp', lessonId);

        try {
            console.log(`üé¨ PRODUCTION START: ${lessonId}`);
            if (!fs.existsSync(path.resolve(process.cwd(), 'temp'))) fs.mkdirSync(path.resolve(process.cwd(), 'temp'));
            if (fs.existsSync(tempDir)) fs.rmSync(tempDir, { recursive: true, force: true });
            fs.mkdirSync(tempDir, { recursive: true });

            await this.supabase.from('lessons').update({ video_status: 'processing' }).eq('lesson_id', lessonId);

            const ai = await this.getGoogleGenAI();
            const scriptRes = await ai.models.generateContent({
                model: 'gemini-3-pro-preview',
                contents: [{ role: 'user', parts: [{ text: `Convert to 30s slides. JSON array: [{"title": "Title", "bullets": ["A", "B"], "image_prompt": "desc", "narration": "text"}] Content: ${summary}` }] }]
            });

            const manifest = JSON.parse(scriptRes.candidates?.[0]?.content?.parts?.[0]?.text?.replace(/```json|```/g, '') || "[]");
            const slideFiles: string[] = [];

            for (let i = 0; i < manifest.length; i++) {
                const slide = manifest[i];
                console.log(`--- Processing Slide ${i + 1} ---`);

                // 1. GENERATE ASSETS
                const imgRes = await ai.models.generateContent({
                    model: 'gemini-3-pro-image-preview',
                    contents: [{ role: 'user', parts: [{ text: slide.image_prompt + " High-fidelity illustration." }] }],
                    config: { responseModalities: ["IMAGE"] }
                });

                const audioRes = await ai.models.generateContent({
                    model: 'gemini-2.5-flash-preview-tts',
                    contents: [{ role: 'user', parts: [{ text: slide.narration }] }],
                    config: {
                        responseModalities: ["AUDIO"],
                        speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Kore' } } }
                    }
                });

                const imgPath = path.join(tempDir, `i${i}.png`);
                const audioPathPCM = path.join(tempDir, `a${i}.pcm`);
                const audioPath = path.join(tempDir, `a${i}.wav`);

                const imgB64 = imgRes.candidates?.[0]?.content?.parts?.find(p => p.inlineData)?.inlineData?.data;
                const audioB64 = audioRes.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;

                if (!imgB64 || !audioB64) throw new Error("Assets failed to generate");

                fs.writeFileSync(imgPath, Buffer.from(imgB64, 'base64'));
                fs.writeFileSync(audioPathPCM, Buffer.from(audioB64, 'base64'));

                // Remove existing output file if it exists
                if (fs.existsSync(audioPath)) fs.unlinkSync(audioPath);

                // Convert PCM to WAV using FFmpeg
                // Gemini TTS returns: s16le format, 24000 Hz, 1 channel (mono)
                console.log(`üîä Converting PCM to WAV ${i}...`);
                await new Promise((res, rej) => {
                    ffmpeg(audioPathPCM)
                        .inputOptions([
                            '-f s16le',      // Input format: signed 16-bit little-endian PCM
                            '-ar 24000',     // Sample rate: 24000 Hz
                            '-ac 1'          // Channels: 1 (mono)
                        ])
                        .audioCodec('pcm_s16le')
                        .audioChannels(1)
                        .audioFrequency(24000)
                        .format('wav')
                        .on('start', (cmd) => console.log('Audio conversion cmd:', cmd.substring(0, 150)))
                        .on('end', () => {
                            console.log(`‚úÖ Converted audio ${i}`);
                            res(true);
                        })
                        .on('error', (err, stdout, stderr) => {
                            console.error("Audio conversion error:", err.message);
                            console.error("Audio stderr:", stderr);
                            rej(err);
                        })
                        .save(audioPath);
                });

                // 2. RENDER SLIDE - Use system FFmpeg instead of ffmpeg-static
                const slidePath = path.join(tempDir, `s${i}.mp4`);

                // Get font path without escaping (we'll handle in command)
                const rawFontPath = this.getSystemFont();

                // Clean text thoroughly
                const cleanTitle = slide.title.replace(/[^a-zA-Z0-9 ]/g, " ");
                const cleanBullets = slide.bullets.map((b: string) =>
                    b.replace(/[^a-zA-Z0-9 ]/g, " ")
                );

                // Build drawtext filters
                let drawtextFilters = `drawtext=fontfile=${rawFontPath}:text='${cleanTitle}':x=100:y=150:fontsize=65:fontcolor=0x22c55e`;

                cleanBullets.forEach((bullet: string, idx: number) => {
                    drawtextFilters += `,drawtext=fontfile=${rawFontPath}:text='‚Ä¢ ${bullet}':x=100:y=${350 + (idx * 80)}:fontsize=36:fontcolor=white`;
                });

                // Complete filter chain
                const filterComplex = `[0:v]scale=960:960:force_original_aspect_ratio=increase,crop=960:960[scaled];color=s=1920x1080:c=0x062012[bg];[bg][scaled]overlay=900:60,${drawtextFilters}[outv]`;

                console.log('üîç Filter:', filterComplex.substring(0, 150) + '...');

                await new Promise((res, rej) => {
                    const cmd = ffmpeg()
                        .input(imgPath)
                        .inputOptions(['-loop 1'])
                        .input(audioPath)
                        .complexFilter(filterComplex)
                        .outputOptions([
                            '-map [outv]',
                            '-map 1:a',
                            '-t 30',
                            '-pix_fmt yuv420p',
                            '-c:v libx264',
                            '-c:a aac',
                            '-b:a 128k',
                            '-preset ultrafast',
                            '-shortest'
                        ])
                        .save(slidePath);

                    cmd.on('start', (commandLine) => {
                        console.log('üé• FFmpeg command:', commandLine.substring(0, 200) + '...');
                    });

                    cmd.on('end', () => {
                        console.log(`‚úÖ Rendered slide ${i}`);
                        res(true);
                    });

                    cmd.on('error', (err, stdout, stderr) => {
                        console.error("‚ùå FFmpeg Error:", err.message);
                        console.error("Stderr:", stderr);
                        rej(err);
                    });
                });

                slideFiles.push(slidePath);
            }

            // 3. STITCH & UPLOAD
            const finalPath = path.join(tempDir, 'final.mp4');
            const stitcher = ffmpeg();
            slideFiles.forEach(f => stitcher.input(f));

            stitcher
                .on('end', async () => {
                    const videoBuffer = fs.readFileSync(finalPath);
                    const storagePath = `${lessonId}/slides_${Date.now()}.mp4`;
                    await this.supabase.storage.from('seeker').upload(storagePath, videoBuffer, { contentType: 'video/mp4' });
                    const { data } = this.supabase.storage.from('seeker').getPublicUrl(storagePath);

                    await this.supabase.from('lessons').update({
                        video_url: data.publicUrl,
                        video_status: 'ready',
                        video_manifest: manifest
                    }).eq('lesson_id', lessonId);

                    fs.rmSync(tempDir, { recursive: true, force: true });
                    this.processingQueue.delete(lessonId);
                    console.log('üéâ PRODUCTION COMPLETE');
                })
                .on('error', (err) => {
                    console.error('‚ùå Stitching failed:', err);
                    throw err;
                })
                .mergeToFile(finalPath);

        } catch (e) {
            console.error('‚ùå CRITICAL FAILURE:', e);
            await this.supabase.from('lessons').update({ video_status: 'failed' }).eq('lesson_id', lessonId);
            this.processingQueue.delete(lessonId);
            // Keep temp files for debugging
            // if (fs.existsSync(tempDir)) fs.rmSync(tempDir, { recursive: true, force: true });
        }
    }

    async createPodcast(lessonId: string, summary: string, title: string) {
        const tempDir = path.resolve(process.cwd(), 'temp', `pod_${lessonId}`);

        try {
            console.log(`üéôÔ∏è PODCAST PRODUCTION START: ${lessonId}`);
            if (!fs.existsSync(tempDir)) fs.mkdirSync(tempDir, { recursive: true });

            // 1. Update status to processing
            await this.supabase.from('lessons').update({ podcast_status: 'processing' }).eq('lesson_id', lessonId);

            const ai = await this.getGoogleGenAI();

            // 2. Generate a Podcast Script (Dialogue)
            const scriptRes = await ai.models.generateContent({
                model: 'gemini-2.0-flash', // Use Flash for fast text generation
                contents: [{
                    role: 'user', parts: [{
                        text: `
                    Create a 1-minute podcast script based on this lesson: "${title}". 
                    Context: ${summary}
                    
                    The hosts are Alex (enthusiastic, curious) and Sam (expert, calm).
                    Format the output strictly as a dialogue like this:
                    Alex: [text]
                    Sam: [text]
                ` }]
                }]
            });

            const transcript = scriptRes.candidates?.[0]?.content?.parts?.[0]?.text || '';

            // 3. Generate Multi-Speaker Audio
            console.log("üîä Generating Multi-speaker TTS...");
            const audioRes = await ai.models.generateContent({
                model: 'gemini-2.5-flash-preview-tts',
                contents: [{
                    parts: [{
                        text: `
                    # DIRECTOR'S NOTES
                    Style: Engaging educational podcast. 
                    Alex sounds youthful and Sam sounds mature and authoritative.
    
                    # TRANSCRIPT
                    ${transcript}
                ` }]
                }],
                config: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        multiSpeakerVoiceConfig: {
                            speakerVoiceConfigs: [
                                { speaker: 'Alex', voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Puck' } } },
                                { speaker: 'Sam', voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Charon' } } }
                            ]
                        }
                    }
                }
            });

            const audioB64 = audioRes.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
            if (!audioB64) throw new Error("Podcast audio failed to generate");

            const pcmPath = path.join(tempDir, 'pod.pcm');
            const wavPath = path.join(tempDir, 'pod.wav');
            fs.writeFileSync(pcmPath, Buffer.from(audioB64, 'base64'));

            // 4. Convert PCM to WAV/MP3 (Gemini returns 24kHz Mono)
            await new Promise((res, rej) => {
                ffmpeg(pcmPath)
                    .inputOptions(['-f s16le', '-ar 24000', '-ac 1'])
                    .toFormat('mp3')
                    .on('end', res)
                    .on('error', rej)
                    .save(wavPath);
            });

            // 5. Upload to Supabase
            const audioBuffer = fs.readFileSync(wavPath);
            const storagePath = `${lessonId}/podcast_${Date.now()}.mp3`;

            await this.supabase.storage.from('seeker').upload(storagePath, audioBuffer, { contentType: 'audio/mpeg' });
            const { data } = this.supabase.storage.from('seeker').getPublicUrl(storagePath);

            // 6. Final Update
            await this.supabase.from('lessons').update({
                podcast_url: data.publicUrl,
                podcast_status: 'ready'
            }).eq('lesson_id', lessonId);

            console.log('üéâ PODCAST COMPLETE');
            fs.rmSync(tempDir, { recursive: true, force: true });

        } catch (e) {
            console.error('‚ùå PODCAST FAILURE:', e);
            await this.supabase.from('lessons').update({ podcast_status: 'failed' }).eq('lesson_id', lessonId);
        }
    }

    // Add these to your SlidesService class

    async createComic(lessonId: string, aiNotes: string, title: string) {
        const tempDir = path.resolve(process.cwd(), 'temp', `comic_${lessonId}`);

        try {
            console.log(`üé® [${lessonId}] COMIC PRODUCTION BEGAN: Topic - ${title}`);
            if (!fs.existsSync(tempDir)) fs.mkdirSync(tempDir, { recursive: true });

            // 1. Set Status to Processing
            await this.supabase.from('lessons').update({ comic_status: 'processing' }).eq('lesson_id', lessonId);

            const ai = await this.getGoogleGenAI();

            // --- STAGE 1: THE DIRECTOR (Analysis & Storyboarding) ---
            // This stage determines the "Visual Identity" based on the content.
            const directorPrompt = `
                Analyze the following educational topic and notes:
                TOPIC: ${title}
                NOTES: ${aiNotes.substring(0, 1500)}
    
                Your goal is to storyboard a 5-page educational comic.
                
                STEP 1: Identify the CORE AESTHETIC. 
                - If historical: Use an era-appropriate art style (e.g., Oil painting, Ink wash, or Vintage sketch).
                - If scientific: Use a technical, clean, or diagrammatic style.
                - If sports/action: Use high-energy Manga/Dynamic styles.
                
                STRICT RULE: Do NOT use generic sci-fi, space, or superhero tropes unless the notes are specifically about those topics. Ground all visuals in the geography and era of the notes.
    
                STEP 2: Define Visual Anchors.
                - Describe 1-2 consistent characters and the specific color palette (e.g., "Deep ochres and forest greens for Buganda history").
    
                STEP 3: Storyboard 5 Pages.
                - Page 1 must be a cinematic Title Page.
                - Pages 2-5 must explain the key facts from the notes visually.
    
                OUTPUT JSON ONLY:
                {
                  "thematic_era": "string",
                  "style_guide": "detailed description of art style",
                  "visual_anchors": "detailed character/env descriptions for consistency",
                  "pages": [
                    { "page": 1, "panel_desc": "visual description", "caption": "educational text" }
                  ]
                }
            `;

            const boardRes = await ai.models.generateContent({
                model: 'gemini-3-pro-preview',
                contents: [{ role: 'user', parts: [{ text: directorPrompt }] }]
            });
            const manifest = JSON.parse(boardRes.candidates?.[0]?.content?.parts?.[0]?.text?.replace(/```json|```/g, '').trim() || '{}');

            console.log(`üìã [${lessonId}] Style Selected: ${manifest.thematic_era} - ${manifest.style_guide}`);

            // --- STAGE 2: THE ARTIST (Stateful Continuity) ---
            const pageUrls: string[] = [];

            for (const pageData of manifest.pages) {
                console.log(`üñåÔ∏è [${lessonId}] Rendering Page ${pageData.page}/5...`);

                const artistPrompt = `
                    You are a master comic artist. Your style for this project is: ${manifest.style_guide}.
                    Visual Anchors for continuity: ${manifest.visual_anchors}.
                    Era: ${manifest.thematic_era}.
                    Maintain 100% visual consistency. Do not deviate from the established era.
                    
                    Generate Page ${pageData.page}. 
                    Visual Description: ${pageData.panel_desc}.
                    Include this Caption/Text in a professional layout: "${pageData.caption}".
                    Style Reminder: ${manifest.style_guide}.
                    Requirement: High-fidelity, 2-3 panels, cinematic lighting.
                `;

                const result = await ai.models.generateContent({
                    model: 'gemini-3-pro-image-preview',
                    contents: [{ role: 'user', parts: [{ text: artistPrompt }] }],
                    config: { responseModalities: ["IMAGE"] }
                });

                const imgPart = result.candidates?.[0]?.content?.parts?.find(p => p.inlineData);
                if (!imgPart?.inlineData?.data) throw new Error(`Artist failed to render page ${pageData.page}`);

                // Upload to Supabase Storage
                const buffer = Buffer.from(imgPart.inlineData.data, 'base64');
                const storagePath = `comics/${lessonId}/p${pageData.page}_${Date.now()}.jpg`;

                await this.supabase.storage
                    .from('seeker')
                    .upload(storagePath, buffer, { contentType: 'image/jpeg', upsert: true });

                const { data: { publicUrl } } = this.supabase.storage.from('seeker').getPublicUrl(storagePath);
                pageUrls.push(publicUrl);
            }

            // 3. Final Database Update
            await this.supabase.from('lessons').update({
                comic_pages: pageUrls,
                comic_status: 'ready'
            }).eq('lesson_id', lessonId);

            console.log(`üéâ [${lessonId}] COMIC COMPLETE: ${pageUrls.length} pages generated.`);

            // Cleanup local temp files
            if (fs.existsSync(tempDir)) fs.rmSync(tempDir, { recursive: true, force: true });

        } catch (error) {
            console.error(`‚ùå [${lessonId}] COMIC FAILED:`, error);
            await this.supabase.from('lessons').update({ comic_status: 'failed' }).eq('lesson_id', lessonId);
            if (fs.existsSync(tempDir)) fs.rmSync(tempDir, { recursive: true, force: true });
        }
    }

    // Inside SlidesService class...

async generateSkillTree(courseId: string) {
    // 1. Fetch existing modules and lessons
    const { data: course } = await this.supabase
        .from('courses')
        .select(`*, modules(id, title, order_index, lesson_plans(id, title, order_index, status))`)
        .eq('id', courseId)
        .single();

    if (!course) throw new Error("Course not found");

    // Check if tree already exists
    const { data: existingTree } = await this.supabase.from('skill_trees').select('id').eq('course_id', courseId).single();
    if (existingTree) return { message: 'Tree already exists', treeId: existingTree.id };

    // 2. Prepare data for Gemini to Layout
    const flatLessons = course.modules
        .sort((a, b) => a.order_index - b.order_index)
        .flatMap((m, mIdx) => 
            m.lesson_plans
                .sort((a, b) => a.order_index - b.order_index)
                .map((l, lIdx) => ({ 
                    id: l.id, 
                    title: l.title, 
                    module: m.title, 
                    globalIndex: mIdx * 10 + lIdx // Helper for linear dependency
                }))
        );

    // 3. AI Layout Generation
    const ai = await this.getGoogleGenAI();
    const prompt = `
        I have a list of lessons for a course: "${course.title}".
        List: ${JSON.stringify(flatLessons.map(l => ({ id: l.id, title: l.title })))}

        I need you to arrange these into a visual Skill Tree RPG-style map.
        
        Rules:
        1. The output must be a JSON array of nodes.
        2. x_position: 0-100 (horizontal canvas percent).
        3. y_position: 0-100 (vertical canvas percent). Top (0) is start, Bottom (100) is end.
        4. Organize them logically. Usually earlier lessons at top, later at bottom. Branches are cool.
        5. "dependencies": array of IDs of the *immediate* parent node(s).
        
        Output JSON only:
        [
            { "lesson_id": "uuid", "x": 50, "y": 10, "dependencies": [] }
        ]
    `;

    const result = await ai.models.generateContent({
        model: 'gemini-3-pro-preview',
        contents: [{ role: 'user', parts: [{ text: prompt }] }]
    });

    const layout = JSON.parse(result.candidates?.[0]?.content?.parts?.[0]?.text?.replace(/```json|```/g, '').trim() || "[]");

    // 4. Save to DB
    const { data: newTree } = await this.supabase.from('skill_trees').insert({ course_id: courseId }).select().single();

    const nodesToInsert = layout.map((node: any) => {
        const originalLesson = flatLessons.find(l => l.id === node.lesson_id);
        // Fallback status logic
        const lessonStatus = course.modules.flatMap(m => m.lesson_plans).find(l => l.id === node.lesson_id)?.status || 'locked';

        return {
            tree_id: newTree.id,
            lesson_plan_id: node.lesson_id,
            label: originalLesson?.title || "Unknown Lesson",
            x_position: node.x,
            y_position: node.y,
            dependencies: node.dependencies,
            status: lessonStatus
        };
    });

    await this.supabase.from('skill_nodes').insert(nodesToInsert);
    return { message: 'Tree Generated', treeId: newTree.id };
}
}

// END OF FILE: src/slides/slides.service.ts
// ==========================================================================

// FILE: src/video/video.controller.ts
// --------------------------------------------------------------------------

import { Controller, Post, Body } from '@nestjs/common';
import { VideoService } from './video.service';

@Controller('video')
export class VideoController {
  constructor(private readonly videoService: VideoService) {}

  @Post('generate-cinematic')
  async generateCinematic(
    @Body() body: { lessonId: string; summary: string; title: string; studentId: string }
  ) {
    // Run async to avoid gateway timeouts
    this.videoService.produceCinematicExplainer(
      body.lessonId,
      body.summary,
      body.title,
      body.studentId,
    );
    return { message: 'Veo Cinematic production sequence initiated' };
  }
}

// END OF FILE: src/video/video.controller.ts
// ==========================================================================

// FILE: src/video/video.module.ts
// --------------------------------------------------------------------------

import { Module } from '@nestjs/common';
import { VideoController } from './video.controller';
import { VideoService } from './video.service';

@Module({
  controllers: [VideoController],
  providers: [VideoService],
})
export class VideoModule {}

// END OF FILE: src/video/video.module.ts
// ==========================================================================

// FILE: src/video/video.service.ts
// --------------------------------------------------------------------------

// FILE: src/video/video.service.ts
// --------------------------------------------------------------------------

import { Injectable, OnModuleInit } from '@nestjs/common';
import { createClient } from '@supabase/supabase-js';
import * as fs from 'fs';
import * as path from 'path';
import ffmpeg from 'fluent-ffmpeg';
import { execSync } from 'child_process';

@Injectable()
export class VideoService implements OnModuleInit {
    private supabase = createClient(
        process.env.SUPABASE_URL!,
        process.env.SUPABASE_SERVICE_ROLE_KEY!,
    );

    async onModuleInit() {
        try {
            const ffmpegPath = execSync('which ffmpeg').toString().trim();
            ffmpeg.setFfmpegPath(ffmpegPath);
            console.log('‚úÖ VideoService: Veo 3.1 Engine Initialized');
        } catch (e) {
            console.error('‚ùå FFmpeg not found on system.');
        }
    }

    private async getGoogleAIClient() {
        const { GoogleGenAI } = await import('@google/genai');
        // We use v1alpha for Veo and Gemini 3 features
        return new GoogleGenAI({
            apiKey: process.env.GEMINI_API_KEY!,
            apiVersion: 'v1alpha',
        });
    }

    async produceCinematicExplainer(
        lessonId: string,
        summary: string,
        title: string,
        studentId: string,
    ) {
        const tempDir = path.resolve(process.cwd(), 'temp', `veo_${lessonId}`);
        console.log(`üé¨ [${lessonId}] PRODUCTION BEGAN: Independent Scene Generation Mode`);

        try {
            if (!fs.existsSync(tempDir)) fs.mkdirSync(tempDir, { recursive: true });

            // 1. Fetch Student Context
            const { data: student } = await this.supabase
                .from('students')
                .select('interest')
                .eq('student_id', studentId)
                .single();
            const userInterests = student?.interest?.join(', ') || 'Cinematic Realism';

            await this.supabase.from('lessons').update({ animated_video_status: 'processing' }).eq('lesson_id', lessonId);

            const ai = await this.getGoogleAIClient();

            // 2. STAGE 1: Visual Identity Extraction
            console.log(`üìù [${lessonId}] Designing Visual Anchors...`);
            const identityPrompt = `
                Analyze lesson: "${title}". Context: ${summary}. Style: ${userInterests}.
                Identify ONE Main Protagonist and ONE primary Location.
                Return JSON ONLY: 
                {
                    "protagonist_description": "detailed physical description including clothing, age, hair, facial features",
                    "location_description": "detailed environmental description",
                    "art_style": "consistent visual style (e.g. 3D Animation, Studio Ghibli, Pixar, or Hyper-realism)"
                }
            `;
            const idRes = await ai.models.generateContent({
                model: 'gemini-3-pro-preview',
                contents: [{ role: 'user', parts: [{ text: identityPrompt }] }]
            });

            const idText = idRes.candidates?.[0]?.content?.parts?.[0]?.text?.replace(/```json|```/g, '').trim();
            if (!idText) throw new Error("Failed to generate Visual Identity JSON");
            const visualId = JSON.parse(idText);

            console.log(`‚úÖ [${lessonId}] Visual Identity:`, visualId);

            // 3. STAGE 2: Generate 2x2 Character Reference Grid (The "Character DNA")
            console.log(`üé® [${lessonId}] Generating 2x2 Character Reference Grid...`);
            const charGridPrompt = `A professional 2x2 character reference sheet showing the same character from 4 different angles arranged in a grid:
- Top-left: Front view facing camera
- Top-right: Side profile (left side)
- Bottom-left: 3/4 three-quarter view
- Bottom-right: Back view

Character description: ${visualId.protagonist_description}
Art style: ${visualId.art_style}

Requirements:
- All 4 views must show the EXACT same character with identical features, clothing, and proportions
- Clean white background
- Professional reference sheet layout
- High detail and clarity
- Consistent lighting across all views`;

            const charGridRes = await ai.models.generateContent({
                model: 'gemini-3-pro-image-preview',
                contents: [{ role: 'user', parts: [{ text: charGridPrompt }] }],
                config: { responseModalities: ["IMAGE"] }
            });
            const charGridB64 = charGridRes.candidates?.[0]?.content?.parts?.find(p => p.inlineData)?.inlineData?.data;
            if (!charGridB64) throw new Error('No character reference grid generated');

            console.log(`‚úÖ [${lessonId}] 2x2 Character Grid created`);

            // 4. STAGE 3: Scripting (4 scenes, 8 seconds each)
            console.log(`üìù [${lessonId}] Drafting 4-scene script (8s per scene)...`);
            const scriptPrompt = `
                Write a 4-scene video script based on: ${summary}. 
                Title: ${title}
                Protagonist: ${visualId.protagonist_description}
                Location: ${visualId.location_description}
                Art Style: ${visualId.art_style}
                
                REQUIREMENTS:
                1. Each scene is exactly 8 seconds long
                2. Create a cohesive narrative that flows naturally from scene 1 to scene 4
                3. Each scene should have clear action and purpose
                4. Include dialogue and sound effects that enhance the storytelling
                5. Maintain character consistency throughout
                
                Output JSON Array ONLY (no markdown, no explanation):
                [
                    {
                        "scene": 1,
                        "action_prompt": "Detailed visual description of what happens in this scene, including camera angles, character actions, and environment. Be specific about composition and framing.",
                        "dialogue_sfx": "Exact dialogue in quotes and sound effects description. Example: A character says 'Hello there!' The sound of footsteps echoing."
                    }
                ]
            `;
            const scriptRes = await ai.models.generateContent({
                model: 'gemini-3-pro-preview',
                contents: [{ role: 'user', parts: [{ text: scriptPrompt }] }]
            });
            const scriptText = scriptRes.candidates?.[0]?.content?.parts?.[0]?.text?.replace(/```json|```/g, '').trim();
            if (!scriptText) throw new Error("Failed to generate Script JSON");
            const script = JSON.parse(scriptText);

            console.log(`‚úÖ [${lessonId}] Script generated with ${script.length} scenes`);

            // 5. STAGE 4: Independent Scene Generation Loop
            const videoClips: string[] = [];

            for (let i = 0; i < script.length; i++) {
                const scene = script[i];
                console.log(`üé• [${lessonId}] Scene ${i + 1}/${script.length}: Generating...`);

                // A. Generate Scene Thumbnail (The "Anchor")
                console.log(`   üì∏ [${lessonId}] Creating thumbnail anchor for scene ${i + 1}...`);
                const thumbPrompt = `${scene.action_prompt}
                
Style: ${visualId.art_style}
Location: ${visualId.location_description}
Lighting: Cinematic, professional
Character: ${visualId.protagonist_description}

Create a single frame that captures the key moment of this scene. This will be used as the starting frame for video generation.`;

                const thumbRes = await ai.models.generateContent({
                    model: 'gemini-3-pro-image-preview',
                    contents: [{ role: 'user', parts: [{ text: thumbPrompt }] }],
                    config: { responseModalities: ["IMAGE"] }
                });
                const thumbB64 = thumbRes.candidates?.[0]?.content?.parts?.find(p => p.inlineData)?.inlineData?.data;
                if (!thumbB64) throw new Error(`No thumbnail generated for scene ${i + 1}`);

                console.log(`   ‚úÖ [${lessonId}] Thumbnail created for scene ${i + 1}`);

                // B. Veo 3.1 Video Generation with Both Reference Images
                console.log(`   üé¨ [${lessonId}] Generating video for scene ${i + 1}...`);
                const veoPayload: any = {
                    model: 'veo-3.1-generate-preview',
                    prompt: `${scene.action_prompt}. ${scene.dialogue_sfx}. Maintain character consistency. High quality cinematic video, 24fps, smooth motion.`,
                    config: {
                        resolution: '720p',
                        aspectRatio: '16:9',
                        durationSeconds: 8,
                        personGeneration: "allow_adult",
                        referenceImages: [
                            {
                                // Character DNA Grid - ensures 3D character consistency
                                image: {
                                    imageBytes: charGridB64,
                                    mimeType: "image/png"
                                },
                                referenceType: "asset"
                            },
                            {
                                // Scene Thumbnail - ensures correct composition and lighting
                                image: {
                                    imageBytes: thumbB64,
                                    mimeType: "image/png"
                                },
                                referenceType: "asset"
                            }
                        ]
                    }
                };

                let operation = await ai.models.generateVideos(veoPayload);

                // Polling for completion
                process.stdout.write(`   ‚è≥ [${lessonId}] Waiting for scene ${i + 1}`);
                while (!operation.done) {
                    process.stdout.write(".");
                    await new Promise(r => setTimeout(r, 10000));

                    operation = await ai.operations.getVideosOperation({
                        operation: operation,
                    });
                }
                console.log(" ‚úÖ Done!");

                if (!operation.response?.generatedVideos?.[0]) {
                    throw new Error(`No video generated for scene ${i + 1}`);
                }

                const currentClip = operation.response.generatedVideos[0];
                const clipPath = path.join(tempDir, `scene_${i + 1}.mp4`);

                if (!currentClip.video) {
                    throw new Error(`No video file available for scene ${i + 1}`);
                }

                // Download the clip locally
                await ai.files.download({ file: currentClip.video, downloadPath: clipPath });
                
                videoClips.push(clipPath);
                console.log(`   ‚úÖ [${lessonId}] Scene ${i + 1} downloaded to ${clipPath}`);
            }

            // 6. STAGE 5: Stitch Videos with FFmpeg (Stream Copy Method)
            console.log(`üîó [${lessonId}] Stitching ${videoClips.length} scenes together...`);
            
            const listFilePath = path.join(tempDir, 'clips.txt');
            const fileListContent = videoClips.map(clipPath => `file '${path.basename(clipPath)}'`).join('\n');
            fs.writeFileSync(listFilePath, fileListContent);

            const finalOutputPath = path.join(tempDir, 'final_cinematic.mp4');

            await new Promise<void>((resolve, reject) => {
                ffmpeg()
                    .input(listFilePath)
                    .inputOptions(['-f concat', '-safe 0'])
                    .outputOptions([
                        '-c copy',  // Stream copy - NO re-encoding, preserves quality and audio
                    ])
                    .output(finalOutputPath)
                    .on('start', (cmd) => {
                        console.log(`   üéûÔ∏è  [${lessonId}] FFmpeg started: ${cmd}`);
                    })
                    .on('end', () => {
                        console.log(`   ‚úÖ [${lessonId}] FFmpeg stitching complete`);
                        resolve();
                    })
                    .on('error', (err) => {
                        console.error(`   ‚ùå [${lessonId}] FFmpeg error:`, err);
                        reject(err);
                    })
                    .run();
            });

            // 7. STAGE 6: Upload to Supabase
            console.log(`‚òÅÔ∏è  [${lessonId}] Final cinematic produced. Uploading...`);
            const videoBuffer = fs.readFileSync(finalOutputPath);
            const storagePath = `${lessonId}/cinematic_${Date.now()}.mp4`;

            await this.supabase.storage.from('seeker').upload(storagePath, videoBuffer, { contentType: 'video/mp4' });
            const { data: urlData } = this.supabase.storage.from('seeker').getPublicUrl(storagePath);

            await this.supabase.from('lessons').update({
                animated_video_url: urlData.publicUrl,
                animated_video_status: 'ready',
            }).eq('lesson_id', lessonId);

            console.log(`üéâ [${lessonId}] PRODUCTION COMPLETE: ${urlData.publicUrl}`);
            console.log(`üìä [${lessonId}] Stats: ${script.length} scenes √ó 8s = ${script.length * 8}s total video`);

            // Cleanup
            if (fs.existsSync(tempDir)) {
                fs.rmSync(tempDir, { recursive: true, force: true });
                console.log(`üßπ [${lessonId}] Temporary files cleaned up`);
            }

        } catch (error) {
            console.error(`‚ùå [${lessonId}] PRODUCTION FAILED:`, error);
            await this.supabase.from('lessons').update({ animated_video_status: 'failed' }).eq('lesson_id', lessonId);
            
            // Cleanup on failure
            if (fs.existsSync(tempDir)) {
                fs.rmSync(tempDir, { recursive: true, force: true });
            }
            
            throw error;
        }
    }
}

// END OF FILE: src/video/video.service.ts
// ==========================================================================

// FILE: test/app.e2e-spec.ts
// --------------------------------------------------------------------------

import { Test, TestingModule } from '@nestjs/testing';
import { INestApplication } from '@nestjs/common';
import request from 'supertest';
import { App } from 'supertest/types';
import { AppModule } from './../src/app.module';

describe('AppController (e2e)', () => {
  let app: INestApplication<App>;

  beforeEach(async () => {
    const moduleFixture: TestingModule = await Test.createTestingModule({
      imports: [AppModule],
    }).compile();

    app = moduleFixture.createNestApplication();
    await app.init();
  });

  it('/ (GET)', () => {
    return request(app.getHttpServer())
      .get('/')
      .expect(200)
      .expect('Hello World!');
  });
});


// END OF FILE: test/app.e2e-spec.ts
// ==========================================================================

// FILE: test/jest-e2e.json
// --------------------------------------------------------------------------

{
  "moduleFileExtensions": ["js", "json", "ts"],
  "rootDir": ".",
  "testEnvironment": "node",
  "testRegex": ".e2e-spec.ts$",
  "transform": {
    "^.+\\.(t|j)s$": "ts-jest"
  }
}


// END OF FILE: test/jest-e2e.json
// ==========================================================================

// FILE: tsconfig.build.json
// --------------------------------------------------------------------------

{
  "extends": "./tsconfig.json",
  "exclude": ["node_modules", "test", "dist", "**/*spec.ts"]
}


// END OF FILE: tsconfig.build.json
// ==========================================================================

// FILE: tsconfig.json
// --------------------------------------------------------------------------

{
  "compilerOptions": {
    "module": "nodenext",
    "moduleResolution": "nodenext",
    "resolvePackageJsonExports": true,
    "esModuleInterop": true,
    "isolatedModules": true,
    "declaration": true,
    "removeComments": true,
    "emitDecoratorMetadata": true,
    "experimentalDecorators": true,
    "allowSyntheticDefaultImports": true,
    "target": "ES2023",
    "sourceMap": true,
    "outDir": "./dist",
    "baseUrl": "./",
    "incremental": true,
    "skipLibCheck": true,
    "strictNullChecks": true,
    "forceConsistentCasingInFileNames": true,
    "noImplicitAny": false,
    "strictBindCallApply": false,
    "noFallthroughCasesInSwitch": false
  }
}


// END OF FILE: tsconfig.json
// ==========================================================================

